{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Libraries\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi']= 150\n",
    "import numpy as np\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer.mcmc.api import MCMC\n",
    "from pyro.infer.mcmc import NUTS, HMC\n",
    "import torch\n",
    "import torch.distributions.constraints as constraints\n",
    "from torch.nn.functional import pad\n",
    "from tqdm import trange\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "# For ADVI\n",
    "from pyro.infer import SVI, Trace_ELBO, TraceEnum_ELBO\n",
    "from pyro.contrib.autoguide import AutoDiagonalNormal\n",
    "from pyro.optim import Adam\n",
    "\n",
    "# For GP\n",
    "import pyro.contrib.gp as gp\n",
    "\n",
    "# Default to double precision for torch objects.\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_grid(X, n, return_each=False, eps=0):\n",
    "    x0, x1 = np.meshgrid(np.linspace(X[:, 0].min()-eps, X[:, 0].max()+eps, n),\n",
    "                         np.linspace(X[:, 1].min()-eps, X[:, 1].max()+eps, n))\n",
    "    \n",
    "    Y = np.stack([x0.ravel(), x1.ravel()], axis=-1)\n",
    "    \n",
    "    if return_each:\n",
    "        return Y, x0, x1\n",
    "    else:\n",
    "        return Y\n",
    "\n",
    "def predict(samples, i, X, Xnew, eps=1e-6):\n",
    "    kernel = gp.kernels.RBF(2, samples['alpha'][i], samples['rho'][i])\n",
    "    Nnew = Xnew.shape[0]\n",
    "    \n",
    "    f = compute_f(samples['alpha'][i],\n",
    "                  samples['rho'][i],\n",
    "                  samples['beta'][i],\n",
    "                  samples['eta'][i], X)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        gpr = gp.models.GPRegression(X, f, kernel)\n",
    "        mean, cov = gpr(Xnew, full_cov=True)\n",
    "        \n",
    "    fhat = dist.MultivariateNormal(\n",
    "        mean, cov + torch.eye(Nnew) * eps\n",
    "    ).sample()\n",
    "    \n",
    "    return fhat.sigmoid().numpy()\n",
    "\n",
    "def plot_data(X, y, **kwargs):\n",
    "    colors = np.array(['blue', 'red'])\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=colors[y], **kwargs)\n",
    "\n",
    "def plot_kernel_params(samples, algo, kernel_params=['alpha', 'rho', 'beta'],\n",
    "                       figsize=(8, 3)):\n",
    "    plt.figure(figsize=figsize * 1.2)\n",
    "    for i in range(len(kernel_params)):\n",
    "        plt.subplot(1, len(kernel_params), i + 1)\n",
    "        param = kernel_params[i]\n",
    "        plt.hist(samples[param], bins=30, density=True)\n",
    "        plt.xlabel(param)\n",
    "        plt.ylabel('density')\n",
    "        plt.title(f\"Histograhm of {param} ({algo})\")\n",
    "    plt.tight_layout()   \n",
    "\n",
    "def plot_uq(samples, X, Xnew, algo, figsize=np.array([8, 3])):\n",
    "    preds = np.stack([predict(samples, i, X, Xnew)\n",
    "                    for i in trange(samples['rho'].shape[0])])\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.contourf(x0, x1, preds.mean(0).reshape(x0.shape), 101,\n",
    "                cmap=plt.get_cmap('bwr'), vmin=0, vmax=1)\n",
    "    plt.title(f'Posterior Mean function ({algo})')\n",
    "    plt.xticks([]); plt.yticks([])\n",
    "    plt.colorbar()\n",
    "    plot_data(X, y, edgecolor=\"orange\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.contourf(x0, x1, preds.std(0).reshape(x0.shape), 101,\n",
    "                cmap=plt.get_cmap('Oranges'), vmin=0)\n",
    "    plt.title(f'Posterior SD function ({algo})')\n",
    "    plt.xticks([]); plt.yticks([])\n",
    "    plt.colorbar()\n",
    "\n",
    "    plot_data(X, y, edgecolor=\"black\")\n",
    "\n",
    "    plot_kernel_params(samples, algo, figsize=figsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']\n"
     ]
    }
   ],
   "source": [
    "# Make data\n",
    "# X, y = make_moons(n_samples=50, shuffle=True, noise=0.1, random_state=1)\n",
    "from func import get_data\n",
    "\n",
    "# Read data.\n",
    "X_train,y_train,X_test,y_test,age = get_data(True)\n",
    "\n",
    "ind_train = age[0].astype(\"int\")\n",
    "ind_test = age[1].astype(\"int\")\n",
    "\n",
    "# Prepare data for Pyro model\n",
    "n_cat = int(y_train.max())\n",
    "#print('n_cat', n_cat)\n",
    "n_ind = ind_train.max()\n",
    "#print('n_ind', n_ind)\n",
    "X_train_tensor = torch.tensor(X_train.astype('float')).float()\n",
    "y_train_tensor = torch.tensor(y_train).float()\n",
    "#print(y_train_tensor)\n",
    "ind_train = torch.tensor(ind_train) # these are indices, therefore they need to be (long) integers\n",
    "\n",
    "\n",
    "# Make prediction grid.\n",
    "Xnew, x0, x1 = gen_grid(X_train_tensor, 30, return_each=True, eps=0.5)\n",
    "Xnew = torch.from_numpy(Xnew)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sq_exp_kernel(d, alpha, rho):\n",
    "    return alpha * alpha * torch.exp(-0.5 * torch.pow(d / rho, 2))\n",
    "\n",
    "def compute_f(alpha, rho, beta, eta, X):\n",
    "    N = X.shape[0]\n",
    "    D = torch.cdist(X, X)\n",
    "    K = sq_exp_kernel(D, alpha, rho) + torch.eye(N) * 1e-6\n",
    "    L = K.cholesky()\n",
    "    return L.matmul(eta) + beta\n",
    "\n",
    "# GP Binary Classifier.\n",
    "def gpc(X, y):\n",
    "    N = y.shape[0]\n",
    "    \n",
    "    # Priors.\n",
    "    alpha = pyro.sample('alpha', dist.LogNormal(0, 1))\n",
    "    rho = pyro.sample('rho', dist.LogNormal(0, 1))\n",
    "    beta = pyro.sample('beta', dist.Normal(0, 1))\n",
    "\n",
    "    with pyro.plate('latent_response', N):\n",
    "        eta = pyro.sample('eta', dist.Normal(0, 1))\n",
    "\n",
    "    # Latent function.\n",
    "    f = compute_f(alpha, rho, beta, eta, X)\n",
    "   \n",
    "    with pyro.plate('response', N):\n",
    "        pyro.sample('obs', dist.Bernoulli(logits=f), obs=y)\n",
    "\n",
    "def gpc_modified(*args, **kwargs):\n",
    "    # Run the original model\n",
    "    result = gpc(*args, **kwargs)\n",
    "    \n",
    "    # Detach any tensors in the result\n",
    "    if isinstance(result, torch.Tensor):\n",
    "        result = result.detach()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warmup:   0%|          | 0/1000 [00:00, ?it/s]c:\\Users\\emmab\\anaconda3\\lib\\site-packages\\pyro\\poutine\\subsample_messenger.py:70: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  result = torch.tensor(0.0, device=self.device)\n",
      "Warmup:   1%|‚ñè         | 13/1000 [00:20,  1.64s/it, step size=5.00e-02, acc. prob=0.564]"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "you can only change requires_grad flags of leaf variables. If you want to use a computed variable in a subgraph that doesn't require differentiation use var_no_grad = var.detach().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:11\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\emmab\\anaconda3\\lib\\site-packages\\pyro\\poutine\\messenger.py:32\u001b[0m, in \u001b[0;36m_context_wrap\u001b[1;34m(context, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_context_wrap\u001b[39m(\n\u001b[0;32m     26\u001b[0m     context: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessenger\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     27\u001b[0m     fn: Callable,\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;241m*\u001b[39margs: Any,\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m     30\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m context:\n\u001b[1;32m---> 32\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\emmab\\anaconda3\\lib\\site-packages\\pyro\\infer\\mcmc\\api.py:565\u001b[0m, in \u001b[0;36mMCMC.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m optional(\n\u001b[0;32m    557\u001b[0m     pyro\u001b[38;5;241m.\u001b[39mvalidation_enabled(\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisable_validation),\n\u001b[0;32m    558\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisable_validation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    562\u001b[0m     \u001b[38;5;66;03m# This also resolves \"RuntimeError: Cowardly refusing to serialize non-leaf tensor which\u001b[39;00m\n\u001b[0;32m    563\u001b[0m     \u001b[38;5;66;03m# requires_grad\", which happens with `jit_compile` under PyTorch 1.7\u001b[39;00m\n\u001b[0;32m    564\u001b[0m     args \u001b[38;5;241m=\u001b[39m [arg\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_tensor(arg) \u001b[38;5;28;01melse\u001b[39;00m arg \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[1;32m--> 565\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x, chain_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampler\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    566\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m num_samples[chain_id] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    567\u001b[0m             num_samples[chain_id] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\emmab\\anaconda3\\lib\\site-packages\\pyro\\infer\\mcmc\\api.py:225\u001b[0m, in \u001b[0;36m_UnarySampler.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    223\u001b[0m logger \u001b[38;5;241m=\u001b[39m initialize_logger(logger, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, progress_bar)\n\u001b[0;32m    224\u001b[0m hook_w_logging \u001b[38;5;241m=\u001b[39m _add_logging_hook(logger, progress_bar, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook)\n\u001b[1;32m--> 225\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m _gen_samples(\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel,\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarmup_steps,\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples,\n\u001b[0;32m    229\u001b[0m     hook_w_logging,\n\u001b[0;32m    230\u001b[0m     i \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_chains \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;241m*\u001b[39margs,\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    233\u001b[0m ):\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m sample, i  \u001b[38;5;66;03m# sample, chain_id\u001b[39;00m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel\u001b[38;5;241m.\u001b[39mcleanup()\n",
      "File \u001b[1;32mc:\\Users\\emmab\\anaconda3\\lib\\site-packages\\pyro\\infer\\mcmc\\api.py:152\u001b[0m, in \u001b[0;36m_gen_samples\u001b[1;34m(kernel, warmup_steps, num_samples, hook, chain_id, *args, **kwargs)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m {name: params[name]\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m save_params}\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(warmup_steps):\n\u001b[1;32m--> 152\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[43mkernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    153\u001b[0m     hook(\n\u001b[0;32m    154\u001b[0m         kernel,\n\u001b[0;32m    155\u001b[0m         params,\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWarmup [\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(chain_id) \u001b[38;5;28;01mif\u001b[39;00m chain_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWarmup\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    157\u001b[0m         i,\n\u001b[0;32m    158\u001b[0m     )\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_samples):\n",
      "File \u001b[1;32mc:\\Users\\emmab\\anaconda3\\lib\\site-packages\\pyro\\infer\\mcmc\\hmc.py:391\u001b[0m, in \u001b[0;36mHMC.sample\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;66;03m# Temporarily disable distributions args checking as\u001b[39;00m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;66;03m# NaNs are expected during step size adaptation\u001b[39;00m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m optional(pyro\u001b[38;5;241m.\u001b[39mvalidation_enabled(\u001b[38;5;28;01mFalse\u001b[39;00m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_t \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warmup_steps):\n\u001b[1;32m--> 391\u001b[0m     z_new, r_new, z_grads_new, potential_energy_new \u001b[38;5;241m=\u001b[39m \u001b[43mvelocity_verlet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpotential_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmass_matrix_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkinetic_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    397\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[43mz_grads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mz_grads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;66;03m# apply Metropolis correction.\u001b[39;00m\n\u001b[0;32m    401\u001b[0m     r_new_unscaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmass_matrix_adapter\u001b[38;5;241m.\u001b[39munscale(r_new)\n",
      "File \u001b[1;32mc:\\Users\\emmab\\anaconda3\\lib\\site-packages\\pyro\\ops\\integrator.py:39\u001b[0m, in \u001b[0;36mvelocity_verlet\u001b[1;34m(z, r, potential_fn, kinetic_grad, step_size, num_steps, z_grads)\u001b[0m\n\u001b[0;32m     37\u001b[0m r_next \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_steps):\n\u001b[1;32m---> 39\u001b[0m     z_next, r_next, z_grads, potential_energy \u001b[38;5;241m=\u001b[39m \u001b[43m_single_step_verlet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43mz_next\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr_next\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpotential_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkinetic_grad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_grads\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m z_next, r_next, z_grads, potential_energy\n",
      "File \u001b[1;32mc:\\Users\\emmab\\anaconda3\\lib\\site-packages\\pyro\\ops\\integrator.py:61\u001b[0m, in \u001b[0;36m_single_step_verlet\u001b[1;34m(z, r, potential_fn, kinetic_grad, step_size, z_grads)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m site_name \u001b[38;5;129;01min\u001b[39;00m z:\n\u001b[0;32m     59\u001b[0m     z[site_name] \u001b[38;5;241m=\u001b[39m z[site_name] \u001b[38;5;241m+\u001b[39m step_size \u001b[38;5;241m*\u001b[39m r_grads[site_name]  \u001b[38;5;66;03m# z(n+1)\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m z_grads, potential_energy \u001b[38;5;241m=\u001b[39m \u001b[43mpotential_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpotential_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m site_name \u001b[38;5;129;01min\u001b[39;00m r:\n\u001b[0;32m     63\u001b[0m     r[site_name] \u001b[38;5;241m=\u001b[39m r[site_name] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m step_size \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m-\u001b[39mz_grads[site_name])  \u001b[38;5;66;03m# r(n+1)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\emmab\\anaconda3\\lib\\site-packages\\pyro\\ops\\integrator.py:93\u001b[0m, in \u001b[0;36mpotential_grad\u001b[1;34m(potential_fn, z)\u001b[0m\n\u001b[0;32m     91\u001b[0m grads \u001b[38;5;241m=\u001b[39m grad(potential_energy, z_nodes)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m z_nodes:\n\u001b[1;32m---> 93\u001b[0m     \u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequires_grad_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(z_keys, grads)), potential_energy\u001b[38;5;241m.\u001b[39mdetach()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: you can only change requires_grad flags of leaf variables. If you want to use a computed variable in a subgraph that doesn't require differentiation use var_no_grad = var.detach()."
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "\n",
    "### HMC ###\n",
    "pyro.clear_param_store()\n",
    "\n",
    "# Set random seed for reproducibility.\n",
    "pyro.set_rng_seed(2)\n",
    "\n",
    "# Set up HMC sampler.\n",
    "# kernel = HMC(gpc, step_size=0.05, trajectory_length=1, adapt_step_size=False, adapt_mass_matrix=False, jit_compile=True)\n",
    "kernel = HMC(gpc_modified, step_size=0.05, trajectory_length=1, adapt_step_size=False, adapt_mass_matrix=False, jit_compile=True)\n",
    "hmc = MCMC(kernel, num_samples=500, warmup_steps=500)\n",
    "hmc.run(X_train_tensor, y_train_tensor.double())\n",
    "\n",
    "# Get posterior samples\n",
    "hmc_posterior_samples = hmc.get_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
